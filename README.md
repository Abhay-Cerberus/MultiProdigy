## ğŸ“¦ MultiProdigy AI Agents Framework

**MultiProdigy** is a modular, schema-driven, multi-agent framework built with Pydantic. It enables scalable and orchestrated communication between autonomous agents with a shared message bus, runtime engine, and support infrastructure.

------

## âœ¨ Key Features

- **ğŸ¤– Unified LLM Integration**: Support for OpenAI, Gemini, Anthropic, Ollama, HuggingFace with consistent API
- **ğŸ“Š Real-time Observability**: Dashboard and network visualization for agent monitoring
- **ğŸ”§ Plugin-based Architecture**: Modular design with easy extensibility
- **âœ… Schema Validation**: Pydantic-based type safety and validation
- **ğŸŒ Multi-Agent Communication**: Scalable message bus for agent coordination
- **ğŸ“ˆ Performance Monitoring**: Structured logging and tracing
- **ğŸ›¡ï¸ Error Handling**: Comprehensive error tracking and recovery

## ğŸš€ Quick Start

```bash
# Run the working demo with real LLM responses
python demo/run_working_demo.py

# Then open the dashboard
# http://localhost:5000
```

## ğŸ“‹ Available Demos

- **ğŸ¯ Working Demo**: `python demo/run_working_demo.py` - Shows real LLM responses (recommended)
- **ğŸ“Š Observability Demo**: `python demo/run_observability_demo.py` - Dashboard and monitoring
- **ğŸ¤– LLM System Demo**: `python demo/run_llm_demo.py` - Tests all LLM providers
- **âš¡ Quick Test**: `python demo/test_llm_quick.py` - Verify system setup

See [demo/README.md](demo/README.md) for detailed demo descriptions.

-------

## ğŸ“š Documentation

- [ğŸ“š **Documentation Hub**](docs/README.md) - Complete documentation index
- [ğŸš€ **Getting Started**](docs/getting_started.md) - Quick start guide  
- [ğŸ”§ **Installation**](docs/installation.md) - Detailed setup instructions
- [ğŸ—ï¸ **Architecture**](docs/architecture.md) - System design overview
- [ğŸ—‚ï¸ **API Reference**](docs/modules_reference.md) - Complete module reference
- [ğŸ¯ **Demo Guide**](docs/sample_agent_demo.md) - Explore all demos
- [ğŸ“Š **Observability**](docs/observability/user_guide.md) - Monitoring and debugging 

## ğŸ”‘ API Key Setup

To experience real AI responses, set up your API keys:

```bash
# Recommended: Gemini 2.0 Flash (fast and capable)
export GEMINI_API_KEY="your-gemini-api-key"

# Alternative: OpenAI GPT models
export OPENAI_API_KEY="your-openai-api-key"

# Get keys from:
# Gemini: https://makersuite.google.com/app/apikey
# OpenAI: https://platform.openai.com/api-keys
```

## ğŸ¯ What You'll Experience

### **Real AI Responses**
```
ğŸ¤– Gemini 2.0 Flash Response:

Artificial Intelligence (AI) is a branch of computer science that aims to create 
machines capable of performing tasks that typically require human intelligence,
such as learning, reasoning, problem-solving, and language understanding...
```

### **Live Monitoring Dashboard**
- Real-time agent communication tracking
- Interactive network graph visualization
- Performance metrics and error monitoring
- Timeline view of all interactions

### **Multi-Provider Support**
- **API Providers**: OpenAI, Gemini, Anthropic
- **Local Models**: Ollama, HuggingFace Transformers
- **Testing**: Mock AI for development
- **Unified Interface**: Same code works with any provider

## ğŸ—ï¸ Architecture Highlights

- **ğŸ¤– Agent-Based**: Modular agents with automatic observability
- **ğŸ”„ Message Bus**: Scalable communication with built-in tracing
- **ğŸ§  LLM Integration**: Unified interface for all AI providers
- **ğŸ“Š Real-time Monitoring**: Zero-config dashboard and visualization
- **âœ… Type Safety**: Pydantic models throughout
- **ğŸ›¡ï¸ Error Handling**: Graceful degradation and recovery

## ğŸš€ Use Cases

- **ğŸ”¬ Research**: AI-powered research agents with real-time collaboration
- **ğŸ“Š Analysis**: Data analysis agents with intelligent insights
- **ğŸ¤– Automation**: Task automation with LLM-powered decision making
- **ğŸ’¬ Chatbots**: Multi-agent conversational systems
- **ğŸ” Monitoring**: Real-time system observability and debugging
- **ğŸ§ª Testing**: LLM provider comparison and benchmarking

--------

## ğŸ¤ Contributing

We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for details.

---

**ğŸ‰ Ready to build intelligent agents?** Start with:
```bash
python demo/run_working_demo.py
```
